{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 16:02:19.473707: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-14 16:02:20.128400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from arcgis.gis import GIS\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar GPU\n",
    "tf.config.list_physical_devices(\"GPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONEXIÓN A AGOL Y DESCARGAR CONTENIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train_a_tensorflow-lite_model_for_identifying_plant_species.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gis = GIS(\"home\")\n",
    "\n",
    "training_data = gis.content.get(\"81932a51f77b4d2d964218a7c5a4af17\")\n",
    "\n",
    "data_path = training_data.download(save_path=\"data\")\n",
    "data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Descomprimir\n",
    "import zipfile\n",
    "\n",
    "if data_path.endswith(\".zip\"):\n",
    "    with zipfile.ZipFile(data_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"data/extracted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETECTAR RUTAS DINÁMICAMENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/arcgis/data/extracted/train/images')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT = Path(os.getcwd())\n",
    "extracted_dir = list(ROOT.rglob(\"extracted\"))[0]\n",
    "\n",
    "BASE_DIR = extracted_dir / \"train\" / \"images\"\n",
    "BASE_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBTENER CLASES E IMÁGENES IGNORANDO LOS XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39354, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = sorted([d.name for d in BASE_DIR.iterdir() if d.is_dir()])\n",
    "num_classes = len(class_names)\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    class_dir = BASE_DIR / class_name\n",
    "    for img_path in class_dir.glob(\"*.jpg\"):\n",
    "        image_paths.append(str(img_path))\n",
    "        labels.append(idx)\n",
    "\n",
    "len(image_paths), num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREAR DATASET TF.DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 16:05:42.902162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0001:00:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = (256, 256)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMAGE_SIZE)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "dataset = dataset.shuffle(len(image_paths), seed=42)\n",
    "dataset = dataset.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Split 80 / 20\n",
    "train_size = int(0.8 * len(image_paths))\n",
    "\n",
    "train_ds = dataset.take(train_size)\n",
    "val_ds   = dataset.skip(train_size)\n",
    "\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "val_ds   = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AÑADIR DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16705208/16705208 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    input_shape=(*IMAGE_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(256,256,3))\n",
    "\n",
    "x = data_augmentation(inputs)\n",
    "x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO FASE 1: TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 16:07:53.935795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8700\n",
      "2026-01-14 16:07:54.045391: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2026-01-14 16:07:54.046199: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2026-01-14 16:07:54.046230: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2026-01-14 16:07:54.046922: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2026-01-14 16:07:54.047076: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984/984 [==============================] - 116s 111ms/step - loss: 2.4639 - accuracy: 0.4057 - val_loss: 1.6292 - val_accuracy: 0.5703\n",
      "Epoch 2/15\n",
      "984/984 [==============================] - 108s 109ms/step - loss: 1.7553 - accuracy: 0.5435 - val_loss: 1.4101 - val_accuracy: 0.6270\n",
      "Epoch 3/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 1.5437 - accuracy: 0.5873 - val_loss: 1.3141 - val_accuracy: 0.6495\n",
      "Epoch 4/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 1.4064 - accuracy: 0.6207 - val_loss: 1.2126 - val_accuracy: 0.6647\n",
      "Epoch 5/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 1.3152 - accuracy: 0.6413 - val_loss: 1.0936 - val_accuracy: 0.7005\n",
      "Epoch 6/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 1.2391 - accuracy: 0.6597 - val_loss: 1.1005 - val_accuracy: 0.7005\n",
      "Epoch 7/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 1.1861 - accuracy: 0.6718 - val_loss: 1.0281 - val_accuracy: 0.7192\n",
      "Epoch 8/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 1.1404 - accuracy: 0.6811 - val_loss: 0.9817 - val_accuracy: 0.7296\n",
      "Epoch 9/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 1.0863 - accuracy: 0.6938 - val_loss: 0.9835 - val_accuracy: 0.7329\n",
      "Epoch 10/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 1.0478 - accuracy: 0.7059 - val_loss: 0.9728 - val_accuracy: 0.7329\n",
      "Epoch 11/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 1.0115 - accuracy: 0.7122 - val_loss: 0.9567 - val_accuracy: 0.7449\n",
      "Epoch 12/15\n",
      "984/984 [==============================] - 109s 111ms/step - loss: 0.9782 - accuracy: 0.7223 - val_loss: 0.9693 - val_accuracy: 0.7356\n",
      "Epoch 13/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.9485 - accuracy: 0.7294 - val_loss: 0.9457 - val_accuracy: 0.7483\n",
      "Epoch 14/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.9151 - accuracy: 0.7367 - val_loss: 0.8825 - val_accuracy: 0.7589\n",
      "Epoch 15/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.9020 - accuracy: 0.7401 - val_loss: 0.9232 - val_accuracy: 0.7564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7b7f1849a7d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINE TUNING A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Descongelar SOLO las últimas 40 capas\n",
    "for layer in base_model.layers[:-40]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in base_model.layers[-40:]:\n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "984/984 [==============================] - 114s 111ms/step - loss: 0.7156 - accuracy: 0.7884 - val_loss: 0.7606 - val_accuracy: 0.7967\n",
      "Epoch 2/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.6540 - accuracy: 0.8093 - val_loss: 0.7220 - val_accuracy: 0.8045\n",
      "Epoch 3/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.6340 - accuracy: 0.8136 - val_loss: 0.7169 - val_accuracy: 0.8023\n",
      "Epoch 4/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.6073 - accuracy: 0.8223 - val_loss: 0.7110 - val_accuracy: 0.8000\n",
      "Epoch 5/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.5979 - accuracy: 0.8219 - val_loss: 0.6976 - val_accuracy: 0.8107\n",
      "Epoch 6/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.5722 - accuracy: 0.8294 - val_loss: 0.6749 - val_accuracy: 0.8169\n",
      "Epoch 7/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.5723 - accuracy: 0.8309 - val_loss: 0.6799 - val_accuracy: 0.8157\n",
      "Epoch 8/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.5612 - accuracy: 0.8325 - val_loss: 0.6679 - val_accuracy: 0.8136\n",
      "Epoch 9/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.5533 - accuracy: 0.8369 - val_loss: 0.6788 - val_accuracy: 0.8111\n",
      "Epoch 10/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.5517 - accuracy: 0.8364 - val_loss: 0.6755 - val_accuracy: 0.8159\n",
      "Epoch 11/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.5390 - accuracy: 0.8404 - val_loss: 0.6564 - val_accuracy: 0.8226\n",
      "Epoch 12/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.5421 - accuracy: 0.8383 - val_loss: 0.6525 - val_accuracy: 0.8216\n",
      "Epoch 13/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.5217 - accuracy: 0.8428 - val_loss: 0.6915 - val_accuracy: 0.8117\n",
      "Epoch 14/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.5279 - accuracy: 0.8435 - val_loss: 0.6482 - val_accuracy: 0.8205\n",
      "Epoch 15/15\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.5181 - accuracy: 0.8447 - val_loss: 0.6489 - val_accuracy: 0.8177\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "history_finetune = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINE TUNING B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:-80]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-80:]:\n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "984/984 [==============================] - 114s 111ms/step - loss: 0.5015 - accuracy: 0.8508 - val_loss: 0.6511 - val_accuracy: 0.8196\n",
      "Epoch 2/8\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.4965 - accuracy: 0.8524 - val_loss: 0.6345 - val_accuracy: 0.8243\n",
      "Epoch 3/8\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.4948 - accuracy: 0.8536 - val_loss: 0.6325 - val_accuracy: 0.8258\n",
      "Epoch 4/8\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.4949 - accuracy: 0.8508 - val_loss: 0.6302 - val_accuracy: 0.8223\n",
      "Epoch 5/8\n",
      "984/984 [==============================] - 112s 114ms/step - loss: 0.4827 - accuracy: 0.8553 - val_loss: 0.6670 - val_accuracy: 0.8132\n",
      "Epoch 6/8\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.4845 - accuracy: 0.8525 - val_loss: 0.6199 - val_accuracy: 0.8314\n",
      "Epoch 7/8\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.4839 - accuracy: 0.8569 - val_loss: 0.6286 - val_accuracy: 0.8226\n",
      "Epoch 8/8\n",
      "984/984 [==============================] - 108s 110ms/step - loss: 0.4743 - accuracy: 0.8588 - val_loss: 0.6390 - val_accuracy: 0.8202\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_finetune_2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GUARDAR EL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: plant_species_tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: plant_species_tf/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"plant_species_tf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERSION A TENSORFLOW LITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 17:17:08.330143: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2026-01-14 17:17:08.330193: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2026-01-14 17:17:08.335060: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: plant_species_tf\n",
      "2026-01-14 17:17:08.369847: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2026-01-14 17:17:08.369890: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: plant_species_tf\n",
      "2026-01-14 17:17:08.424299: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2026-01-14 17:17:08.450250: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2026-01-14 17:17:08.968586: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: plant_species_tf\n",
      "2026-01-14 17:17:09.177565: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 842506 microseconds.\n",
      "2026-01-14 17:17:09.386775: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"plant_species_tf\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"plant_species.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Advanced with GPU support",
   "notebookRuntimeVersion": "12.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
